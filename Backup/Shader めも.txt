


FilterMode が Bilinera の tex2Dlod の lod は0.5で切り上げた値となる
floor(lod + 0.5)と同じ



// int型の割り算や余りの計算をhlslでコンパイルすると結構複雑になる
int a, b;
int result = a / b;
↓
int a, b;
int temp0 = uint(max(a, -a)) / uint(max(b, -b));
int result = ((a ^ b) & 0x80000000) ? -temp0 : temp0;

int a, b;
int result = a % b;
↓
int a, b;
int temp0 = uint(max(a, -a)) % uint(max(b, -b));
int result = (a & 0x80000000) ? -temp0 : temp0;



matrix[0] よりも matrix._11_21_31_41 の方が命令数を節約できる



Tangent (接空間) 座標系

 ↓ transpose(float4x3(wTangent, wBinormal, wNormal, wPos)) で変換

World 座標系



Object (Local) 座標系

 ↓ Model 行列 (UNITY_MATRIX_M) で変換

World 座標系

 ↓ View 行列 (UNITY_MATRIX_V) で変換

View 座標系

 ↓ Projection 行列 (UNITY_MATRIX_P) で変換

Clip 座標系

 ↓ ComputeNonStereoScreenPos 関数で変換 (DesktopかVRかで変わるかも)

Screen 座標系



// Clip 座標系から Screen 座標系へ変換
(cPos.xy / cPos.w) * 0.5 + 0.5
↓
(cPos.xy / cPos.w + 1.0) * 0.5
↓
// ComputeNonStereoScreenPos とほぼ同じ処理
(cPos.xy + cPos.ww) * 0.5 / cPos.w



Shader の頂点ID (SV_VertexID) は、異なるSubMeshでも共通 (たぶん)
Shader のポリゴンID (SV_PrimitiveID) は、異なるSubMeshで共通ではなく、0から始まる



Unity で PSIZE セマンティクスは使えない



透視投影の場合、以下の三つの値はほぼ同じ (多少の誤差は発生する DirectX11のみ確認)
LinearEyeDepth(_CameraDepthTexture[uint2(input.cPos.xy)].r)
Linear01Depth(_CameraDepthTexture[uint2(input.cPos.xy)].r) * _ProjectionParams.z
DecodeFloatRG(_CameraDepthNormalsTexture[uint2(input.cPos.xy)].ba) * _ProjectionParams.z



Camera.depthTextureMode の初期状態は DepthTextureMode.None

DepthTextureMode は Flags 属性付き

DepthTextureMode.Depth
Texture2D _CameraDepthTexture;

DepthTextureMode.DepthNormals
Texture2D _CameraDepthNormalsTexture;

DepthTextureMode.MotionVectors
Texture2D _CameraMotionVectorsTexture;



ShadeSH9などの関数を使用したい場合は、LightMode を ForwardBase にする必要がある



CameraのClearFlagsの挙動
    SkyBox : Depthを初期化した後SkyBoxを描画してからMeshを描画
SolidColor : Depthを初期化した後指定した色で塗りつぶしてからMeshを描画
 DepthOnly : Depthだけ初期化してMeshを描画
Don'tClear : 何も初期化せずにMeshを描画



unity_4LightAtten0 = 25.0 / (Range * Range)
unity_4LightAtten0 * (Range * Range) = 25.0
(Range * Range) = 25.0 / unity_4LightAtten0
Range = sqrt(25.0 / unity_4LightAtten0)



destColor はすでに描画している色
 srcColor は生成した色

Blend srcColorのブレンド係数 destColorのブレンド係数

Blend SrcAlpha OneMinusSrcAlpha
↓
result = srcColor * srcColor.a + destColor * (1.0 - srcColor.a)

Blend OneMinusDstColor OneMinusSrcAlpha
↓
result = srcColor * (1.0 - destColor) + destColor * (1.0 - srcColor.a)



multi_compile や shader_feature の使い方

#pragma multi_compile_local TEST_A TEST_B TEST_C
#pragma shader_feature_local TEST_A TEST_B TEST_C

Material.EnableKeyword や Material.DisableKeyword などのメソッドで、
それぞれのキーワードの有効・無効を切り替えることができる

すべてのキーワードが無効の場合、一番左側にあるキーワード（上の例だと TEST_A）が define される
複数のキーワードが有効になっている場合、有効になっている一番左側にあるキーワードが define される

例外
shader_feature で一つだけキーワードを宣言した場合

#pragma shader_feature_local TEST_A
↓
#pragma shader_feature_local _ TEST_A

このように解釈される



ShaderAPI が DirectX の場合
GL.GetGPUProjectionMatrix は投影行列の形式を OpenGL 形式から Direct3D11 形式に変換する
OpenGL 形式の射影行列をそのまま Camera.projectionMatrix に代入しても問題ないので、自動的に OpenGL 形式から Direct3D11 形式に変換していると考えられる
OpenGL 形式の射影行列を Camera.projectionMatrix に代入する場合は GL.GetGPUProjectionMatrix を使う必要はない
OpenGL 形式の射影行列を Material.SetMatrix でシェーダーに渡す場合に GL.GetGPUProjectionMatrix を使う
Camera.projectionMatrix から得られる射影行列は OpenGL 形式のはず（たぶん）



Projector用MVP行列はShaderAPIに関わらず常にOpenGL系らしい(Unity2019で検証)



V行列はShaderAPIに関わらず不変？（未検証）



PNGとして出力と入力が両方可能な形式
R8G8B8A8_UNorm
R8_UNorm
R16_UNorm



channel0 (TEXCOORD0) 普通のUV座標
channel1 (TEXCOORD1) ライトマップ用UV座標
channel2 (TEXCOORD2) リアルタイムライトマップ用UV座標？



影
UNITY_LIGHTING_COORDS & UNITY_TRANSFER_LIGHTING & UNITY_LIGHT_ATTENUATION
UNITY_TRANSFER_LIGHTINGがLightMode=ForwardAddの時使用不可なので没

LIGHTING_COORDS & TRANSFER_SHADOW & UNITY_LIGHT_ATTENUATION
悪くない

SHADOW_COORDS & TRANSFER_SHADOW & UNITY_LIGHT_ATTENUATION
現時点で最高

SHADOW_COORDS & TRANSFER_SHADOW & SHADOW_ATTENUATION
ForwardBase専用　データ量をかなり小さくできる



DX9
sampler2D Tex0;
float4 color = tex2D(Tex0, xy)

DX11
Texture2D<float4> Tex0 : register(t0);
sampler Tex0Sampler : register(s0);
float4 color = Tex0.Sample(Tex0Sampler, xy)

ShaderLabではDX11をDX9っぽく書けるようにするために色々な関数が追加されている



頂点シェーダーからフラグメントシェーダーに方向を表すベクトルを送る時、
頂点シェーダー側で正規化してさらにフラグメントシェーダー側でも正規化していたのだが、
頂点シェーダー側の正規化は基本的には必要ないかもしれない
それどころか条件によっては、頂点シェーダー側の正規化をしない方が精度が高まるかもしれない



"Queue" = "Overlay+2147479647"
"Queue" = "Overlay+815199"
(8192 * 100 - 1 ?)



Texture2D.Load(int3(cPos.x, cPos.y, mipLevel), int2(offset.x, offset.y));
↓
Texture2D.mips[mipLevel][uint2(input.cPos.xy)];

Texture2D.mips[0][uint2(input.cPos.xy)];
↓
Texture2D[uint2(input.cPos.xy)];



頂点シェーダーからフラグメントシェーダーに方向を表すベクトルを送る時、
頂点シェーダー側で正規化してさらにフラグメントシェーダー側でも正規化していたのだが、
頂点シェーダー側の正規化は基本的には必要ないかもしれない



vPos.z / 140000 = Zファイティングが発生するポリゴン同士の距離の目安



float 32bit浮動小数点
half  16bit浮動小数点
fixed 11bit固定小数点

↑要求精度が高い
位置ベクトル　float
UV座標　　　　float
単位ベクトル　float, half
色　　　　　　half, fixed
↓要求精度が低い



Unityでよく使う圧縮形式

DXT1(BC1)
RGB形式で使える
pixelあたりの情報量は4bit

DXT5(BC3)
RGBA形式で使える
pixelあたりの情報量は8bit

DTXnm
ノーマルマップ用 DTX5と似ているらしい
pixelあたりの情報量は8bit

BC7
RGB,RGBA形式で使える HighQualityCompressionで出現
pixelあたりの情報量は8bit



色空間
色をそのまま足したり掛けたりするのがガンマワークフロー
色をリニア空間に変換（逆ガンマ補正）をしてから足したり掛けたりした後にガンマ空間に変換（ガンマ補正）するのがリニアワークフロー
ガンマワークフローよりリニアワークフローの方が自然に見えるらしい

逆ガンマ補正(Gamma To Linear)で黒っぽくなる
  ガンマ補正(Linear To Gamma)で白っぽくなる

Unityはリニアワークフローを推奨しているがUnity2019のデフォルト設定はガンマワークフローになっている（罠）
VRChatはリニアワークフローである

テクスチャのインポート設定にsRGBのチェックボックスがある
これはこのテクスチャに入っている情報が色なのか数値(ベクトル)なのかを設定する
バンプマップやノーマルマップなどの、色ではなく数値として扱われるテクスチャは逆ガンマ補正されると困るのでsRGBのチェックを外そう

ちなみにガンマワークフローでsRGBのチェックを入れたり外したりしてもなにもおきない

ガンマワークフローで sRGB がオン
テクスチャ                 → シェーダー               → モニター

ガンマワークフローで sRGB がオフ
テクスチャ                 → シェーダー               → モニター

リニアワークフローで sRGB がオン
テクスチャ → 逆ガンマ補正 → シェーダー → ガンマ補正 → モニター

リニアワークフローで sRGB がオフ
テクスチャ                 → シェーダー → ガンマ補正 → モニター

Graphics.Blit

source の sRGB がオフ   dest の sRGB がオフ
source →              → シェーダー →            → dest

source の sRGB がオフ   dest の sRGB がオン
source →              → シェーダー → ガンマ補正 → dest

source の sRGB がオン   dest の sRGB がオフ
source → 逆ガンマ補正 → シェーダー →            → dest

source の sRGB がオン   dest の sRGB がオン
source → 逆ガンマ補正 → シェーダー → ガンマ補正 → dest



UNITY_VERTEX_INPUT_INSTANCE_ID の処理
Stage の入力構造体に変数を追加する

	(defined(UNITY_INSTANCING_ENABLED) || defined(UNITY_PROCEDURAL_INSTANCING_ENABLED) || defined(UNITY_STEREO_INSTANCING_ENABLED)) && defined(SHADER_API_PSSL)
	uint instanceID;

	(defined(UNITY_INSTANCING_ENABLED) || defined(UNITY_PROCEDURAL_INSTANCING_ENABLED) || defined(UNITY_STEREO_INSTANCING_ENABLED)) && !defined(SHADER_API_PSSL)
	uint instanceID : SV_InstanceID;



UNITY_VERTEX_OUTPUT_STEREO の処理
FragmentShaderStage の入力構造体に変数を追加する

	defined(UNITY_STEREO_INSTANCING_ENABLED) && (defined(SHADER_API_GLES3) || defined(SHADER_API_GLCORE))
	uint stereoTargetEyeIndexSV : SV_RenderTargetArrayIndex;
	uint stereoTargetEyeIndex : BLENDINDICES0;

	defined(UNITY_STEREO_INSTANCING_ENABLED) && !(defined(SHADER_API_GLES3) || defined(SHADER_API_GLCORE))
	uint stereoTargetEyeIndex : SV_RenderTargetArrayIndex;

	!defined(UNITY_STEREO_INSTANCING_ENABLED) && defined(UNITY_STEREO_MULTIVIEW_ENABLED)
	uint stereoTargetEyeIndex : BLENDINDICES0;



UNITY_SETUP_INSTANCE_ID(input) の処理
unity_StereoEyeIndex や unity_InstanceID の上書きとその影響を受ける変数やマクロの更新



UNITY_TRANSFER_INSTANCE_ID(input, output) の処理
次の Stage へ instanceID を渡すときに使う

	defined(UNITY_INSTANCING_ENABLED) || defined(UNITY_PROCEDURAL_INSTANCING_ENABLED) || defined(UNITY_STEREO_INSTANCING_ENABLED)
	output.instanceID = UNITY_GET_INSTANCE_ID(input)



UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output) の処理
unity_StereoEyeIndex を FragmentShaderStage へ渡したり、RenderTarget を変更したりする

	defined(UNITY_STEREO_INSTANCING_ENABLED) && (defined(SHADER_API_GLES3) || defined(SHADER_API_GLCORE))
	output.stereoTargetEyeIndexSV = unity_StereoEyeIndex;
	output.stereoTargetEyeIndex = unity_StereoEyeIndex;

	defined(UNITY_STEREO_INSTANCING_ENABLED) && !(defined(SHADER_API_GLES3) || defined(SHADER_API_GLCORE))
	output.stereoTargetEyeIndex = unity_StereoEyeIndex    // ←なぜかセミコロンが無い

	!defined(UNITY_STEREO_INSTANCING_ENABLED) && defined(UNITY_STEREO_MULTIVIEW_ENABLED)
	output.stereoTargetEyeIndex = unity_StereoEyeIndex;


















Render Pipeline
{
    Built-in Render Pipeline

    Scriptable Render Pipeline
    {
        Universal Render Pipeline (URP)
        High-Definition Render Pipeline (HDRP)
        Custom SRP
    }
}

Built-in Render Pipeline
{
    Surface Shader

    Vertex And Fragment Shader
    {
        Always
        Forward
        Deferred
        VertexLit
    }
}








